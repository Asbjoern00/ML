{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBel\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Below is the code for task 3. Several utility functions are created, as well as the class Sample for doing the actual experiment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Initialize paramters\n",
    "n = 100\n",
    "delta = 0.05\n",
    "k = np.ceil(np.log2(   np.sqrt(  n   /  np.log(1/delta))  / 2 ))\n",
    "lambda_grid= (np.ones(int(k))*1/2)**(np.arange(start = 1, stop = int(k+1)))\n",
    "Z_values = np.array([0, 1/2, 1])\n",
    "p_grid = np.arange(0,1.01,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define utility functions\n",
    "\n",
    "#Function for sampling n from a distribution P(Z)\n",
    "def draw_n(Z, p, n):\n",
    "    probs = (1-p)/2 # Compute probabilities for non-central value\n",
    "    distribution = np.array([probs, p, probs]) # compute probability vector for Z\n",
    "    sample = np.random.choice(Z, size = n, p = distribution) # sample from distribution\n",
    "    return sample\n",
    "\n",
    "\n",
    "def kl(p,q): #define kl-function\n",
    "    if p == 1 or p == 0: #handle exceptions\n",
    "        return 0\n",
    "    return(p*np.log(p/q) + (1-p)*np.log((1-p)/(1-q))) # Define kl-function \n",
    "\n",
    "# Function for finding the (upper) inverse of the kl-function\n",
    "# Input phat and z, where the inverse kl-function given phat is calculated at z\n",
    "\n",
    "def klinverse_upper(phat, z):\n",
    "    low = phat # Initialise lowest and highest possible solutions\n",
    "    high = 1\n",
    "    while(high - low > 0.0000001): # Set tolerance to 0.0000001\n",
    "        mid = (high + low)/2 # Find midpoint\n",
    "        if(kl(phat, mid) <= z): # experiment if kl() evaluated on the average is less than given z\n",
    "            low = mid #If lower, raise the low value to the mid value\n",
    "        else:\n",
    "            high = mid # Else lower the high value to the mid value\n",
    "    return(low) # Return the low value, for the maximal p where inequality still holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sampling class for p_hat and v_hat and corresponding bounds with different values of p to try, the values that Z can take, n and delta\n",
    "class Sample:\n",
    "    def __init__(self, p_grid, Z_values, n, delta):\n",
    "        self.p_grid = p_grid\n",
    "        self.Z_values = Z_values\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.k = np.ceil(np.log2(   np.sqrt(  self.n   /  np.log(1/self.delta))  / 2 )) # Calculate k\n",
    "        self.lambda_grid = (np.ones(int(self.k))*1/2)**(np.arange(start = 1, stop = int(self.k+1))) # Calculate lambda grid\n",
    "    \n",
    "    #Method to generate array of p-hats and v-hats\n",
    "    def generate_samples(self):\n",
    "        # Initialize empty arrays\n",
    "        self.p_hat = np.empty(0)\n",
    "        self.v_hat = np.empty(0)\n",
    "        \n",
    "        #Loop over p's in grid\n",
    "        for p in self.p_grid:\n",
    "            n_Z = draw_n(Z = self.Z_values, p=p , n= self.n) # draw samples\n",
    "            p_hat = np.mean(n_Z) # p_hat\n",
    "            self.p_hat = np.append(self.p_hat, p_hat) # append to array\n",
    "            v_hat = np.mean(n_Z**2) # v_hat\n",
    "            self.v_hat =np.append(self.v_hat, v_hat) # append to array\n",
    "\n",
    "    #Method for calculation of Bernstein bound\n",
    "    def bernstein(self):\n",
    "        self.bernstein_bound = np.min(np.array([lambda_*self.v_hat + (np.log(self.k/self.delta))/(lambda_*self.n) for lambda_ in self.lambda_grid]), axis=0)\n",
    "    \n",
    "    #Method for calculation of the kl bound\n",
    "    def kl_calc(self):\n",
    "        self.kl_bound = np.empty(0)\n",
    "        for p_hat in self.p_hat:\n",
    "            bound = klinverse_upper(phat = p_hat, z = np.log(  (self.n+1)  /self.delta)/(self.n)) - p_hat\n",
    "            self.kl_bound = np.append(self.kl_bound, bound)\n",
    "    \n",
    "    #Method for aggregating n samples\n",
    "    def aggregate_n(self,n):\n",
    "        bern_bound = np.empty(0) # init arrays\n",
    "        kl_bound = np.empty(0)\n",
    "        for i in range(n): # repeat n times\n",
    "            self.generate_samples() # generate samples\n",
    "            self.bernstein() # calculate bounds\n",
    "            self.kl_calc()\n",
    "            bern_bound = np.append(bern_bound, self.bernstein_bound) # append to vectors\n",
    "            kl_bound = np.append(kl_bound, self.kl_bound)\n",
    "        bern_bound = np.reshape(bern_bound, (n, len(self.p_grid))) # reshape such that rows correspond to 1 sample\n",
    "        kl_bound = np.reshape(kl_bound, (n,len(self.p_grid)))\n",
    "        self.bern_smooth = np.mean(bern_bound, axis = 0) # take mean over columns\n",
    "        self.kl_smooth = np.mean(kl_bound, axis = 0) # take mean over columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the experiment and calculations\n",
    "experiment = Sample(p_grid=np.arange(0,1.01,0.01), Z_values=Z_values, n= 100, delta=delta) # Initialise class\n",
    "experiment.generate_samples() # Generate samples\n",
    "experiment.bernstein() # calculate bernstein bound\n",
    "experiment.kl_calc() # Calculate kl-bound\n",
    "experiment.aggregate_n(n=1000) # Repeat the experiment 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "plt.plot(experiment.p_grid, experiment.bernstein_bound, label = \"Unexpected Bernstein bound\")\n",
    "plt.plot(experiment.p_grid, experiment.kl_bound, label = \"kl-bound\")\n",
    "plt.xlabel(\"$p_{1/2}$\")\n",
    "plt.ylabel(\"Bound on $p-\\hat{p}_n$\")\n",
    "plt.title(\"Empirical comparison of bounds\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(\"emp.png\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "plt.plot(experiment.p_grid, experiment.bern_smooth, label = \"Unexpected Bernstein bound\")\n",
    "plt.plot(experiment.p_grid, experiment.kl_smooth,  label =\"kl-bound\")\n",
    "plt.xlabel(\"$p_{1/2}$\")\n",
    "plt.ylabel(\"Average bound on $p-\\hat{p}_n$\")\n",
    "plt.title(\"Empirical comparison of smoothed bounds\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(\"emp_smooth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below is the code for task 4. A normalisation function is implemented as well as a function for doing t-sne visualisations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.loadtxt(\"dataset-vis-exam2022.txt\", delimiter=\",\") # load in data\n",
    "# Regular 3d Plot\n",
    "\n",
    "#Split into first and last part of dataset\n",
    "X1 = data[:2000,0]\n",
    "Y1 = data[:2000,1]\n",
    "Z1 = data[:2000,2]\n",
    "\n",
    "X2 = data[2000:,0]\n",
    "Y2 = data[2000:,1]\n",
    "Z2 = data[2000:,2]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "# Plot in 3d-space\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X1, Y1, Z1, s = 3)\n",
    "ax.scatter(X2, Y2, Z2, s = 3)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.savefig(\"original.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Import PCA\n",
    "#PCA on non-standardized data\n",
    "pca = PCA(whiten=False, svd_solver = \"full\", n_components = 2) #Intialize PCA\n",
    "pca.fit(data) #Fit PCA to data\n",
    "pca_projection = pca.transform(data) # Calculate the projection of training data onto first two principal components by matrixmultiplication\n",
    "\n",
    "X1 = pca_projection[:2000,0]\n",
    "Y1 = pca_projection[:2000,1]\n",
    "\n",
    "X2 = pca_projection[2000:,0]\n",
    "Y2 = pca_projection[2000:,1]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X1, Y1, s = 3)\n",
    "ax.scatter(X2, Y2, s = 3)\n",
    "\n",
    "ax.set_xlabel('First principal component')\n",
    "ax.set_ylabel('Second principal component')\n",
    "\n",
    "plt.savefig(\"pca.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on normalized data\n",
    "\n",
    "mu = np.mean(data, axis=0) # Compute mean of each feature\n",
    "sd = np.std(data, axis=0, ddof = 0) # Compute (in-sample) standard deviation of each feature\n",
    "def normalize(X,mean,sd): # Function to normalize array given mean and standard deviation\n",
    "     D = np.diag(1/sd) # diagonalize std deviation vector\n",
    "     return X @ D - mu @ D\n",
    "data_norm = normalize(data, mu, sd)\n",
    "\n",
    "\n",
    "pca_norm = PCA(whiten=False, svd_solver = \"full\", n_components = 2) #Intialize PCA\n",
    "pca_norm.fit(data_norm) #Fit PCA to normalized data\n",
    "pca_projection_norm = pca_norm.transform(data_norm)\n",
    "\n",
    "X1 = pca_projection_norm[:2000,0]\n",
    "Y1 = pca_projection_norm[:2000,1]\n",
    "\n",
    "X2 = pca_projection_norm[2000:,0]\n",
    "Y2 = pca_projection_norm[2000:,1]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X1, Y1, s = 5)\n",
    "ax.scatter(X2, Y2, s = 5)\n",
    "\n",
    "ax.set_xlabel('First principal component')\n",
    "ax.set_ylabel('Second principal component')\n",
    "\n",
    "plt.savefig(\"pca_normalized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def tsne_plot(data, init, perplexity,init_name):\n",
    "\n",
    "    filename = \"tsne\" + init_name + str(perplexity)+\".png\"\n",
    "    \n",
    "    tsne = TSNE(learning_rate=\"auto\", init = init, n_jobs=-1, perplexity=perplexity, random_state=120).fit_transform(data)\n",
    "    X1 = tsne[:2000,0]\n",
    "    Y1 = tsne[:2000,1]\n",
    "\n",
    "    X2 = tsne[2000:,0]\n",
    "    Y2 = tsne[2000:,1]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.scatter(X1, Y1, s = 5)\n",
    "    ax.scatter(X2, Y2, s = 5)\n",
    "    ax.set_title(\"t-SNE, Perplexity=\" + str(perplexity))\n",
    "    ax.set_xlabel(\"t-SNE dimension 1\")\n",
    "    ax.set_ylabel(\"t-SNE dimension 2\")\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perplexity in [32,80,180,280]:\n",
    "    tsne_plot(data=data, init = \"random\", perplexity=perplexity,init_name=\"random\")\n",
    "    tsne_plot(data=data, init = pca_projection_norm, perplexity=perplexity, init_name=\"pca\")\n",
    "    tsne_plot(data, init = pca_projection_norm, perplexity=perplexity, init_name=\"pca_original\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2aaaed62726fa93b23a998d174ead1f45903166052f00f97e926b61978a3bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
